"""
Streaming Executor - æµå¼æ‰§è¡Œå™¨

åŸºäº h2A é˜Ÿåˆ—å®ç°çš„æµå¼ Agent æ‰§è¡Œå™¨ï¼Œæ”¯æŒï¼š
1. å®æ—¶æµå¼è¾“å‡ºï¼ˆè¾¹æ€è€ƒè¾¹è¾“å‡ºï¼‰
2. ä½å»¶è¿Ÿå“åº”ï¼ˆå¿«é€Ÿé€šé“ï¼‰
3. éšæ—¶æ‰“æ–­ï¼ˆsteeringï¼‰
"""

import asyncio
from typing import Optional, AsyncIterator
from dataclasses import dataclass

from llm.base import BaseLLM, Message, ToolDefinition
from tools.registry import ToolRegistry
from utils.h2a_queue import StreamingMessageQueue
from utils.logger import Logger, get_logger

from .base import AgentState
from .executor import AgentExecutor


@dataclass
class StreamEvent:
    """æµå¼äº‹ä»¶"""
    type: str  # "thinking", "tool_call", "tool_result", "complete", "error"
    content: str
    metadata: dict = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class StreamingExecutor(AgentExecutor):
    """
    æµå¼æ‰§è¡Œå™¨
    
    ç»§æ‰¿è‡ª AgentExecutorï¼Œå¢åŠ æµå¼è¾“å‡ºèƒ½åŠ›ã€‚
    
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        executor = StreamingExecutor(llm, tools)
        
        async for event in executor.execute_stream(task):
            if event.type == "thinking":
                print(event.content, end="", flush=True)
            elif event.type == "tool_call":
                print(f"\\nğŸ”§ {event.metadata['tool_name']}")
    """
    
    def __init__(
        self,
        llm: BaseLLM,
        tool_registry: ToolRegistry,
        max_iterations: int = 10,
        verbose: bool = True,
        queue_size: int = 1000,
    ):
        super().__init__(llm, tool_registry, max_iterations, verbose)
        self.queue_size = queue_size
        self._current_queue: Optional[StreamingMessageQueue] = None
    
    async def execute_stream(
        self,
        task: str,
        state: Optional[AgentState] = None,
        context: Optional[str] = None,
    ) -> AsyncIterator[StreamEvent]:
        """
        æµå¼æ‰§è¡Œä»»åŠ¡
        
        Args:
            task: ä»»åŠ¡æè¿°
            state: å¯é€‰çš„å·²æœ‰çŠ¶æ€
            context: é¢å¤–ä¸Šä¸‹æ–‡
            
        Yields:
            StreamEvent: æµå¼äº‹ä»¶
        """
        # åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—
        queue = StreamingMessageQueue(
            max_size=self.queue_size,
            name=f"stream_{task[:20]}"
        )
        self._current_queue = queue
        
        try:
            # åœ¨åå°ä»»åŠ¡ä¸­æ‰§è¡Œ
            execution_task = asyncio.create_task(
                self._execute_with_streaming(task, state, context, queue)
            )
            
            # ä»é˜Ÿåˆ—ä¸­æµå¼è¯»å–äº‹ä»¶
            async for msg in queue:
                if msg is None:
                    break
                
                # è½¬æ¢ä¸º StreamEvent
                event = StreamEvent(
                    type=msg.type.value,
                    content=str(msg.content),
                    metadata=msg.metadata
                )
                
                yield event
                
                # æ£€æŸ¥æ˜¯å¦å®Œæˆ
                if msg.type == StreamingMessageQueue.MessageType.COMPLETE:
                    break
                
                # æ£€æŸ¥æ˜¯å¦è¢«æ‰“æ–­
                if msg.type == StreamingMessageQueue.MessageType.INTERRUPT:
                    execution_task.cancel()
                    break
            
            # ç­‰å¾…æ‰§è¡Œä»»åŠ¡å®Œæˆ
            try:
                await execution_task
            except asyncio.CancelledError:
                pass
        
        finally:
            await queue.close()
            self._current_queue = None
    
    async def _execute_with_streaming(
        self,
        task: str,
        state: Optional[AgentState],
        context: Optional[str],
        queue: StreamingMessageQueue,
    ):
        """å¸¦æµå¼è¾“å‡ºçš„æ‰§è¡Œé€»è¾‘"""
        try:
            # å‘é€å¼€å§‹çŠ¶æ€
            await queue.send_status("started", task=task)
            
            # åˆå§‹åŒ–çŠ¶æ€
            if state is None:
                state = AgentState(max_iterations=self.max_iterations)
            state.start_task(task)
            
            # æ„å»ºåˆå§‹æ¶ˆæ¯
            messages = self._build_initial_messages(task, context)
            tool_definitions = self.tools.get_definitions()
            
            # ä¸»æ‰§è¡Œå¾ªç¯
            while not state.is_complete and state.increment_iteration():
                try:
                    # å‘é€è¿­ä»£çŠ¶æ€
                    await queue.send_status(
                        f"iteration_{state.iteration}",
                        iteration=state.iteration,
                        max_iterations=self.max_iterations
                    )
                    
                    # è°ƒç”¨ LLMï¼ˆè¿™é‡Œå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–ä¸ºæµå¼ï¼‰
                    response = self.llm.chat_sync(
                        messages=messages,
                        tools=tool_definitions,
                        temperature=0.7,
                    )
                    
                    # å‘é€æ€è€ƒå†…å®¹
                    if response.content:
                        await queue.send_text(
                            response.content,
                            type="thinking",
                            iteration=state.iteration
                        )
                        
                        state.history.add_think(response.content)
                        messages.append(Message.assistant(
                            response.content,
                            tool_calls=response.tool_calls if response.has_tool_calls else None
                        ))
                    
                    # å¤„ç†å·¥å…·è°ƒç”¨
                    if response.has_tool_calls:
                        for tc in response.tool_calls:
                            # å‘é€å·¥å…·è°ƒç”¨äº‹ä»¶
                            await queue.send_tool_call(
                                tc.name,
                                tc.arguments,
                                tool_id=tc.id
                            )
                            
                            # æ‰§è¡Œå·¥å…·
                            result = self.tools.execute(tc.name, **tc.arguments)
                            
                            # å‘é€å·¥å…·ç»“æœ
                            await queue.enqueue(
                                StreamingMessageQueue.Message(
                                    type=StreamingMessageQueue.MessageType.TOOL_RESULT,
                                    content=str(result),
                                    metadata={
                                        "tool_name": tc.name,
                                        "success": result.success
                                    }
                                )
                            )
                            
                            # æ›´æ–°æ¶ˆæ¯å†å²
                            messages.append(Message.tool(
                                content=str(result),
                                tool_call_id=tc.id,
                                name=tc.name,
                            ))
                        
                        state.clear_errors()
                        
                        # æ£€æŸ¥æå‰å®Œæˆ
                        self._check_early_completion(state)
                        if state.is_complete:
                            break
                    
                    else:
                        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥æ˜¯å¦å®Œæˆ
                        if self._is_task_complete(response.content, state):
                            state.complete(response.content)
                        else:
                            messages.append(Message.user(
                                "Please continue with the task. Use tools if needed, "
                                "or indicate completion if done."
                            ))
                
                except Exception as e:
                    await queue.enqueue(
                        StreamingMessageQueue.Message(
                            type=StreamingMessageQueue.MessageType.ERROR,
                            content=str(e),
                            metadata={"iteration": state.iteration}
                        )
                    )
                    
                    if not state.record_error():
                        state.complete(f"Task failed after too many errors: {str(e)}")
                        break
                    
                    messages.append(Message.user(
                        f"An error occurred: {str(e)}\n"
                        "Please try a different approach or fix the issue."
                    ))
            
            # æ£€æŸ¥æ˜¯å¦ç”¨å®Œè¿­ä»£æ¬¡æ•°
            if not state.is_complete:
                state.complete(
                    f"Task incomplete after {self.max_iterations} iterations."
                )
            
            # å‘é€å®Œæˆäº‹ä»¶
            await queue.enqueue(
                StreamingMessageQueue.Message(
                    type=StreamingMessageQueue.MessageType.COMPLETE,
                    content=state.final_result or "completed",
                    metadata={
                        "iterations": state.iteration,
                        "success": state.is_complete
                    }
                )
            )
        
        except asyncio.CancelledError:
            # è¢«æ‰“æ–­
            await queue.send_status("cancelled")
            raise
        
        except Exception as e:
            await queue.enqueue(
                StreamingMessageQueue.Message(
                    type=StreamingMessageQueue.MessageType.ERROR,
                    content=f"Fatal error: {str(e)}",
                    metadata={"fatal": True}
                )
            )
            raise
        
        finally:
            await queue.close()
    
    async def interrupt(self):
        """æ‰“æ–­å½“å‰æ‰§è¡Œ"""
        if self._current_queue:
            await self._current_queue.interrupt()
