#!/usr/bin/env python3
"""
æµå¼æ‰§è¡Œæ¼”ç¤º

å±•ç¤º h2A åŒç¼“å†²é˜Ÿåˆ—å’Œæµå¼ Agent çš„èƒ½åŠ›ï¼š
1. å®æ—¶æµå¼è¾“å‡º
2. ä½å»¶è¿Ÿå“åº”
3. éšæ—¶æ‰“æ–­ï¼ˆsteeringï¼‰

è¿è¡Œï¼š
    python examples/streaming_demo.py
"""

import sys
import asyncio
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from utils.h2a_queue import H2AQueue, StreamingMessageQueue
from agent.streaming_executor import StreamingExecutor
from llm.factory import LLMFactory
from tools.registry import create_default_registry
from utils.logger import get_logger


async def demo_basic_h2a():
    """æ¼”ç¤ºåŸºç¡€ h2A é˜Ÿåˆ—ç‰¹æ€§"""
    print("=" * 70)
    print("ğŸ§ª æ¼”ç¤º 1: åŸºç¡€ h2A é˜Ÿåˆ—")
    print("=" * 70)
    
    queue = H2AQueue(max_size=10, name="demo")
    
    # ç”Ÿäº§è€…ä»»åŠ¡
    async def producer():
        for i in range(5):
            await queue.enqueue(f"Message {i}")
            print(f"âœ… ç”Ÿäº§: Message {i}")
            await asyncio.sleep(0.1)
        await queue.close()
    
    # æ¶ˆè´¹è€…ä»»åŠ¡
    async def consumer():
        async for msg in queue:
            if msg is None:
                break
            print(f"ğŸ“¨ æ¶ˆè´¹: {msg}")
            await asyncio.sleep(0.2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    
    # å¹¶å‘è¿è¡Œ
    await asyncio.gather(producer(), consumer())
    
    # æ˜¾ç¤ºç»Ÿè®¡
    stats = queue.get_stats()
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"  æ€»å…¥é˜Ÿ: {stats.total_enqueued}")
    print(f"  æ€»å‡ºé˜Ÿ: {stats.total_dequeued}")
    print(f"  å¿«é€Ÿé€šé“å‘½ä¸­: {stats.fast_path_hits}")
    print(f"  ç¼“å†²åŒºäº¤æ¢: {stats.buffer_swaps}")


async def demo_fast_path():
    """æ¼”ç¤ºå¿«é€Ÿé€šé“ï¼ˆé›¶å»¶è¿Ÿï¼‰"""
    print("\n" + "=" * 70)
    print("ğŸ§ª æ¼”ç¤º 2: å¿«é€Ÿé€šé“ï¼ˆæ¶ˆè´¹è€…å…ˆç­‰å¾…ï¼‰")
    print("=" * 70)
    
    queue = H2AQueue(max_size=10, name="fast_path")
    
    # æ¶ˆè´¹è€…å…ˆç­‰å¾…
    async def waiting_consumer():
        print("ğŸ“¨ æ¶ˆè´¹è€…: å¼€å§‹ç­‰å¾…æ¶ˆæ¯...")
        msg = await queue.dequeue()
        print(f"ğŸ“¨ æ¶ˆè´¹è€…: æ”¶åˆ°æ¶ˆæ¯ '{msg}' ï¼ˆå¿«é€Ÿé€šé“ï¼ï¼‰")
    
    # ç”Ÿäº§è€…ç¨åå‘é€
    async def delayed_producer():
        await asyncio.sleep(0.5)
        print("âœ… ç”Ÿäº§è€…: å‘é€æ¶ˆæ¯")
        await queue.enqueue("å¿«é€Ÿé€šé“æ¶ˆæ¯")
    
    # å…ˆå¯åŠ¨æ¶ˆè´¹è€…ï¼Œå†å¯åŠ¨ç”Ÿäº§è€…
    consumer_task = asyncio.create_task(waiting_consumer())
    await asyncio.sleep(0.1)  # ç¡®ä¿æ¶ˆè´¹è€…å…ˆç­‰å¾…
    producer_task = asyncio.create_task(delayed_producer())
    
    await asyncio.gather(consumer_task, producer_task)
    await queue.close()
    
    stats = queue.get_stats()
    print(f"\nğŸ“Š å¿«é€Ÿé€šé“å‘½ä¸­: {stats.fast_path_hits} / {stats.total_enqueued}")


async def demo_streaming_queue():
    """æ¼”ç¤ºæµå¼æ¶ˆæ¯é˜Ÿåˆ—"""
    print("\n" + "=" * 70)
    print("ğŸ§ª æ¼”ç¤º 3: æµå¼æ¶ˆæ¯é˜Ÿåˆ—")
    print("=" * 70)
    
    queue = StreamingMessageQueue(max_size=100, name="streaming")
    
    # æ¨¡æ‹Ÿ Agent è¾“å‡º
    async def agent_simulator():
        await queue.send_status("å¼€å§‹æ‰§è¡Œä»»åŠ¡")
        await asyncio.sleep(0.1)
        
        await queue.send_text("æ­£åœ¨åˆ†æä»»åŠ¡...")
        await asyncio.sleep(0.2)
        
        await queue.send_tool_call("write_file", {"path": "test.py", "content": "..."})
        await asyncio.sleep(0.1)
        
        await queue.send_text("ä»£ç å·²ç”Ÿæˆ")
        await asyncio.sleep(0.1)
        
        await queue.enqueue(
            StreamingMessageQueue.Message(
                type=StreamingMessageQueue.MessageType.COMPLETE,
                content="ä»»åŠ¡å®Œæˆ"
            )
        )
        await queue.close()
    
    # æ¶ˆè´¹è€…
    async def ui_consumer():
        async for msg in queue:
            if msg is None:
                break
            
            if msg.type == StreamingMessageQueue.MessageType.TEXT:
                print(f"ğŸ’­ æ€è€ƒ: {msg.content}")
            elif msg.type == StreamingMessageQueue.MessageType.TOOL_CALL:
                print(f"ğŸ”§ å·¥å…·: {msg.content['name']}")
            elif msg.type == StreamingMessageQueue.MessageType.STATUS:
                print(f"ğŸ“ çŠ¶æ€: {msg.content}")
            elif msg.type == StreamingMessageQueue.MessageType.COMPLETE:
                print(f"âœ… å®Œæˆ: {msg.content}")
                break
    
    await asyncio.gather(agent_simulator(), ui_consumer())
    
    stats = queue.get_stats()
    print(f"\nğŸ“Š æ¶ˆæ¯æ•°: {stats.total_enqueued}")


async def demo_streaming_agent():
    """æ¼”ç¤ºæµå¼ Agent æ‰§è¡Œ"""
    print("\n" + "=" * 70)
    print("ğŸ§ª æ¼”ç¤º 4: æµå¼ Agentï¼ˆéœ€è¦ API Keyï¼‰")
    print("=" * 70)
    
    try:
        # åˆ›å»ºæµå¼æ‰§è¡Œå™¨
        llm = LLMFactory.create("openai")
        tools = create_default_registry()
        executor = StreamingExecutor(llm, tools, max_iterations=3)
        
        task = "å†™ä¸€ä¸ªç®€å•çš„ Hello World Python è„šæœ¬"
        print(f"ä»»åŠ¡: {task}\n")
        print("-" * 70)
        
        # æµå¼æ‰§è¡Œ
        async for event in executor.execute_stream(task):
            if event.type == "thinking":
                print(f"ğŸ’­ {event.content[:80]}...")
            elif event.type == "tool_call":
                tool_name = event.metadata.get("tool_name", "unknown")
                print(f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")
            elif event.type == "tool_result":
                success = event.metadata.get("success", False)
                status = "âœ…" if success else "âŒ"
                print(f"{status} å·¥å…·ç»“æœ: {event.content[:50]}...")
            elif event.type == "status":
                print(f"ğŸ“ {event.content}")
            elif event.type == "complete":
                print(f"âœ… å®Œæˆ: {event.content}")
            elif event.type == "error":
                print(f"âŒ é”™è¯¯: {event.content}")
        
        print("-" * 70)
        print("æµå¼æ‰§è¡Œå®Œæˆï¼")
    
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥ï¼ˆå¯èƒ½ç¼ºå°‘ API Keyï¼‰: {e}")


async def main():
    """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
    print("\nğŸš€ h2A åŒç¼“å†²å¼‚æ­¥é˜Ÿåˆ—æ¼”ç¤º\n")
    
    # åŸºç¡€æ¼”ç¤ºï¼ˆä¸éœ€è¦ APIï¼‰
    await demo_basic_h2a()
    await demo_fast_path()
    await demo_streaming_queue()
    
    # Agent æ¼”ç¤ºï¼ˆéœ€è¦ APIï¼‰
    print("\næ˜¯å¦è¦è¿è¡Œæµå¼ Agent æ¼”ç¤ºï¼Ÿï¼ˆéœ€è¦æœ‰æ•ˆçš„ API Keyï¼‰")
    print("æŒ‰ Enter ç»§ç»­ï¼ŒCtrl+C è·³è¿‡")
    
    try:
        input()
        await demo_streaming_agent()
    except KeyboardInterrupt:
        print("\nâ­ï¸  è·³è¿‡ Agent æ¼”ç¤º")
    
    print("\n" + "=" * 70)
    print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆ")
    print("=" * 70)
    
    print("\nğŸ’¡ å…³é”®ç‰¹æ€§:")
    print("  1. å¿«é€Ÿé€šé“: æ¶ˆè´¹è€…ç­‰å¾…æ—¶ï¼Œæ¶ˆæ¯é›¶å»¶è¿Ÿç›´è¾¾")
    print("  2. åŒç¼“å†²: å‡å°‘é”ç«äº‰ï¼Œæå‡åå")
    print("  3. æµå¼è¾“å‡º: å®æ—¶åé¦ˆï¼Œæå‡ç”¨æˆ·ä½“éªŒ")
    print("  4. å¯æ‰“æ–­: æ”¯æŒ steeringï¼Œéšæ—¶æ”¹å˜æ–¹å‘")


if __name__ == "__main__":
    asyncio.run(main())
